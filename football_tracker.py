# -*- coding: utf-8 -*-
"""football_tracker.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fE9xvqe1oP-H83zadTttvGaN7cKXIDtj
"""

import os
import argparse
import cv2
import numpy as np
import pandas as pd
from ultralytics import YOLO
from collections import defaultdict
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import seaborn as sns

# --- Constants ---
FIELD_LENGTH = 105  # meters
FIELD_WIDTH = 68    # meters

def get_field_coordinates(pos, frame_shape):
    """Map frame pixels to field meters (Linear Mapping)"""
    if pos is None: return None
    real_x = (pos[0] / frame_shape[1]) * FIELD_LENGTH
    real_y = (pos[1] / frame_shape[0]) * FIELD_WIDTH
    return (real_x, real_y)

def get_zone(field_pos):
    """Calculate 18-Zone index (6 cols x 3 rows)"""
    if field_pos is None: return None
    x, y = field_pos
    col = int(x / (FIELD_LENGTH / 6))
    col = max(0, min(col, 5))
    row = int(y / (FIELD_WIDTH / 3))
    row = max(0, min(row, 2))
    return (row * 6) + col + 1

def stitch_tracks(df, target_id, max_frame_gap=60, max_dist_gap=150):
    """
    [Core Logic] Spatio-temporal Track Stitching
    Reconnects broken tracks based on distance and time proximity.
    """
    target_df = df[df['track_id'] == target_id]
    if target_df.empty: return df, target_id

    last_frame = target_df['frame_id'].max()
    last_row = target_df.loc[target_df['frame_id'] == last_frame].iloc[0]
    last_pos = ((last_row['x1']+last_row['x2'])/2, (last_row['y1']+last_row['y2'])/2)

    # Find candidates in future frames
    candidates = df[
        (df['frame_id'] > last_frame) &
        (df['frame_id'] <= last_frame + max_frame_gap) &
        (df['track_id'] != target_id)
    ]

    if candidates.empty: return df, target_id

    best_match_id = None
    min_dist = float('inf')

    for cand_id in candidates['track_id'].unique():
        cand_track = candidates[candidates['track_id'] == cand_id]
        start_row = cand_track.iloc[0]
        start_pos = ((start_row['x1']+start_row['x2'])/2, (start_row['y1']+start_row['y2'])/2)
        dist = np.sqrt((start_pos[0]-last_pos[0])**2 + (start_pos[1]-last_pos[1])**2)

        if dist < max_dist_gap and dist < min_dist:
            min_dist = dist
            best_match_id = cand_id

    if best_match_id is not None:
        print(f"ðŸ”— STITCHED: Connected ID {target_id} -> New ID {best_match_id} (Gap: {min_dist:.1f}px)")
        df.loc[df['track_id'] == best_match_id, 'track_id'] = target_id
        # Recursive call to find further connections
        return stitch_tracks(df, target_id, max_frame_gap, max_dist_gap)

    return df, target_id

def run_analysis(video_path, target_init_pos, output_path, model_path='yolov10m.pt'):
    # 1. Setup
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"Error: Cannot open video {video_path}")
        return

    orig_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    orig_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS) or 30

    # [Tech] Upscaling for Small Object Detection
    SCALE = 1.5
    new_w, new_h = int(orig_w * SCALE), int(orig_h * SCALE)
    scaled_target_pos = (target_init_pos[0]*SCALE, target_init_pos[1]*SCALE)

    print(f"â–¶ Step 1: Tracking with Upscale x{SCALE}...")
    model = YOLO(model_path)

    raw_data = []
    initial_target_id = None
    frame_id = 0

    while True:
        ret, frame = cap.read()
        if not ret: break

        frame_resized = cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_LINEAR)

        # BoT-SORT Tracking
        results = model.track(frame_resized, persist=True, tracker="botsort.yaml",
                              conf=0.1, iou=0.5, verbose=False, classes=[0])

        if results[0].boxes.id is not None:
            boxes = results[0].boxes.xyxy.cpu().numpy()
            track_ids = results[0].boxes.id.int().cpu().numpy()

            # Initial Target Locking
            if initial_target_id is None:
                min_dist = float('inf')
                best_candidate = None
                for box, tid in zip(boxes, track_ids):
                    cx, cy = (box[0]+box[2])/2, (box[1]+box[3])/2
                    dist = np.sqrt((cx - scaled_target_pos[0])**2 + (cy - scaled_target_pos[1])**2)
                    if dist < (150*SCALE) and dist < min_dist:
                        min_dist = dist
                        best_candidate = int(tid)

                if best_candidate is not None:
                    initial_target_id = best_candidate
                    print(f"Target Locked: ID {initial_target_id}")

            for box, tid in zip(boxes, track_ids):
                raw_data.append([frame_id, box[0], box[1], box[2], box[3], int(tid)])

        frame_id += 1
        if frame_id % 100 == 0: print(f"Processing frame {frame_id}...")

    cap.release()

    if not raw_data or initial_target_id is None:
        print("Target not found.")
        return

    # 2. Post-Processing
    print("\nâ–¶ Step 2: Post-Processing (Stitching & Interpolation)...")
    df = pd.DataFrame(raw_data, columns=['frame_id', 'x1', 'y1', 'x2', 'y2', 'track_id'])

    # Apply Stitching Logic
    df, final_id = stitch_tracks(df, initial_target_id, max_frame_gap=60, max_dist_gap=200)

    target_df = df[df['track_id'] == final_id].copy()
    target_df = target_df.drop_duplicates(subset=['frame_id'], keep='first').set_index('frame_id')

    # Linear Interpolation for missing frames
    full_idx = pd.RangeIndex(start=0, stop=frame_id)
    target_df = target_df.reindex(full_idx)
    target_df[['x1','y1','x2','y2']] = target_df[['x1','y1','x2','y2']].interpolate(method='linear')
    target_df = target_df.ffill().bfill()

    # 3. Visualization & Export
    # (Simplified for script: saves data to CSV instead of rendering video to keep code clean)
    csv_output = output_path.replace('.mp4', '.csv')
    target_df.to_csv(csv_output)
    print(f"Analysis Data Saved to {csv_output}")

    # Generate Heatmap Plot
    plot_results(target_df, new_w, new_h, output_path.replace('.mp4', '_report.png'))

def plot_results(df, frame_w, frame_h, save_path):
    # Convert back to original scale and map to field
    final_positions = []
    for _, row in df.iterrows():
        cx, cy = (row['x1']+row['x2'])/2, (row['y1']+row['y2'])/2
        field_pos = get_field_coordinates((cx, cy), (frame_h, frame_w))
        if field_pos: final_positions.append(field_pos)

    if not final_positions: return

    plt.style.use('dark_background')
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.set_facecolor('darkgreen')
    ax.set_xlim(0, FIELD_LENGTH); ax.set_ylim(FIELD_WIDTH, 0)

    # Draw Field Lines (Simplified)
    ax.add_patch(patches.Rectangle((0, 0), FIELD_LENGTH, FIELD_WIDTH, edgecolor='white', facecolor='none'))
    ax.plot([FIELD_LENGTH/2, FIELD_LENGTH/2], [0, FIELD_WIDTH], color='white')

    # Draw Trajectory
    xs, ys = zip(*final_positions)
    sns.kdeplot(x=xs, y=ys, cmap="Reds", fill=True, alpha=0.4, ax=ax)
    ax.plot(xs, ys, color='yellow', linewidth=1.5, alpha=0.8)

    plt.title("Player Movement Heatmap & Trajectory")
    plt.savefig(save_path)
    print(f"Report Image Saved to {save_path}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Advanced Football Player Tracker")
    parser.add_argument('--video', type=str, required=True, help="Path to input video")
    parser.add_argument('--tx', type=int, required=True, help="Target Player Initial X")
    parser.add_argument('--ty', type=int, required=True, help="Target Player Initial Y")
    parser.add_argument('--output', type=str, default="output.mp4", help="Output path")

    args = parser.parse_args()

    run_analysis(args.video, (args.tx, args.ty), args.output)